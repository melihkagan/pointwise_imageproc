{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 926, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                 | 0/159 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part1_video.mp4.\n",
      "MoviePy - Writing audio in part1_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                     | 0/181 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video part1_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part1_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "background = cv2.imread('Malibu.jpg')\n",
    "#plt.imshow(background)\n",
    "#cv2.imshow('Background Image Window', background)\n",
    "#cv2.waitKey(0)\n",
    "\n",
    "background_height = background.shape[0]\n",
    "background_width = background.shape[1]\n",
    "ratio = 360/background_height\n",
    "background = cv2.resize(background, (int(background_width*ratio),360))\n",
    "print(background.shape)\n",
    "\n",
    "imageslist = []\n",
    "i = 0\n",
    "while 1: # loop through cat frames\n",
    "    image=cv2.imread('cat/cat_'+ str(i) + '.png')\n",
    "    if image is None:\n",
    "        break\n",
    "    i = i+1\n",
    "    image_g_channel = image[:, :,1]\n",
    "    image_r_channel = image[:, :,0]\n",
    "    foreground = np.logical_or(image_g_channel < 180 , image_r_channel > 150)\n",
    "    nonzero_x , nonzero_y = np.nonzero(foreground)\n",
    "    nonzerocatvalues = image[nonzero_x, nonzero_y, : ]\n",
    "    new_frame = background.copy()\n",
    "    new_frame[nonzero_x, nonzero_y, :] = nonzerocatvalues\n",
    "    new_frame = new_frame[:,:,[2, 1, 0]]\n",
    "    imageslist.append(new_frame)\n",
    "clip = mpy.ImageSequenceClip( imageslist , fps = 25)\n",
    "audio = mpy.AudioFileClip('selfcontrol_part.wav').set_duration( clip.duration )\n",
    "clip = clip.set_audio(audioclip=audio )\n",
    "clip.write_videofile('part1_video.mp4', codec='libx264')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 926, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                 | 0/159 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part2_video.mp4.\n",
      "MoviePy - Writing audio in part2_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                     | 0/181 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video part2_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part2_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "background = cv2.imread('Malibu.jpg')\n",
    "background_height = background.shape[0]\n",
    "background_width = background.shape[1]\n",
    "ratio = 360/background_height\n",
    "background = cv2.resize(background, (int(background_width*ratio),360))\n",
    "print(background.shape)\n",
    "\n",
    "imageslist = []\n",
    "i = 0\n",
    "while 1:\n",
    "    image=cv2.imread('cat/cat_'+ str(i) + '.png')\n",
    "    if image is None:\n",
    "        break\n",
    "    i = i+1\n",
    "    \n",
    "    #place the reflected cat to the right side\n",
    "    mirror_im = cv2.flip(image,1)\n",
    "    green_im = np.zeros((360,286,3), np.uint8)\n",
    "    green_im[:,0:286]= (0,255,0)\n",
    "    mirror_im = cv2.hconcat([green_im, mirror_im])\n",
    "    \n",
    "    #at first tries i thinked of shifting right but instead of this i choose concatenating with green image\n",
    "        #M = np.float32([[1,0,286],[0,1,0]])\n",
    "        #rows,cols,value = mirror_im.shape\n",
    "        #mirror_im = cv2.warpAffine(mirror_im,M,(cols,rows))\n",
    "    \n",
    "    with_myself = mirror_im.copy()\n",
    "    with_myself[0:image.shape[0],0:image.shape[1]-110,:] = image[0:image.shape[0],0:image.shape[1]-110,:]\n",
    "    #i left 110 more pixels to right cat to see its head shaking better , otherwise it was cropping by orginal\n",
    "    #cat figures\n",
    "    image = with_myself\n",
    "    #same for the rest\n",
    "    image_g_channel = image[:, :,1]\n",
    "    image_r_channel = image[:, :,0]\n",
    "    foreground = np.logical_or(image_g_channel < 180 , image_r_channel > 150)\n",
    "    nonzero_x , nonzero_y = np.nonzero(foreground)\n",
    "    nonzerocatvalues = image[nonzero_x, nonzero_y, : ]\n",
    "    new_frame = background.copy()\n",
    "    new_frame[nonzero_x, nonzero_y, :] = nonzerocatvalues\n",
    "    new_frame = new_frame[:,:,[2, 1, 0]]\n",
    "    imageslist.append(new_frame)\n",
    "clip = mpy.ImageSequenceClip( imageslist , fps = 25)\n",
    "audio = mpy.AudioFileClip('selfcontrol_part.wav').set_duration( clip.duration )\n",
    "clip = clip.set_audio(audioclip=audio )\n",
    "clip.write_videofile('part2_video.mp4', codec='libx264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 926, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                 | 0/159 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part3_video.mp4.\n",
      "MoviePy - Writing audio in part3_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                     | 0/181 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video part3_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part3_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def darker(pix,g):\n",
    "    if (pix-g) <0 :\n",
    "        return 0\n",
    "    else:\n",
    "        return (pix-g)\n",
    "def darker_f_g_channel(pix,g): # at first the aim of this func was to keep green screen\n",
    "    if (pix >= 235):\n",
    "        return pix\n",
    "    elif (pix-g) < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (pix-g)\n",
    "\n",
    "g=90 # paremater for brightness\n",
    "darker_vec = np.vectorize(darker)\n",
    "darker_g_vec = np.vectorize(darker_f_g_channel)\n",
    "\n",
    "background = cv2.imread('Malibu.jpg')\n",
    "background_height = background.shape[0]\n",
    "background_width = background.shape[1]\n",
    "ratio = 360/background_height\n",
    "background = cv2.resize(background, (int(background_width*ratio),360))\n",
    "print(background.shape)\n",
    "\n",
    "imageslist = []\n",
    "i = 0\n",
    "while 1:\n",
    "    image=cv2.imread('cat/cat_'+ str(i) + '.png')\n",
    "    if image is None:\n",
    "        break\n",
    "    i = i+1\n",
    "    \n",
    "    mirror_im = cv2.flip(image,1)\n",
    "    green_im = np.zeros((360,286,3), np.uint8)\n",
    "    green_im[:,0:286]= (0,255,0)\n",
    "    mirror_im = cv2.hconcat([green_im, mirror_im])\n",
    "    \n",
    "    mirror_g_channel = mirror_im[:, :, 1]\n",
    "    mirror_r_channel = mirror_im[:, :, 0]\n",
    "    mirror_b_channel = mirror_im[:, :, 2]\n",
    "    #vectorization to apply darker transform function\n",
    "    darker_cat_g = darker_g_vec(mirror_g_channel,g)\n",
    "    darker_cat_r = darker_vec(mirror_r_channel,g)\n",
    "    darker_cat_b = darker_vec(mirror_b_channel,g)\n",
    "    \n",
    "    darker_cat = np.dstack((darker_cat_r,darker_cat_g,darker_cat_b))\n",
    "    #only use darker cat values in frames\n",
    "    with_myself = mirror_im.copy()\n",
    "    foreground = np.logical_or(mirror_g_channel < 180 , mirror_r_channel > 150)\n",
    "    n_x,n_y = np.nonzero(foreground)\n",
    "    darker_cat_values = darker_cat[n_x, n_y, :]\n",
    "    with_myself[n_x,n_y, : ] = darker_cat_values\n",
    "    #and the left part, bright cat\n",
    "    with_myself[0:image.shape[0],0:image.shape[1]-110,:] = image[0:image.shape[0],0:image.shape[1]-110,:]\n",
    "\n",
    "    image = with_myself\n",
    "    #same for the rest\n",
    "    image_g_channel = image[:, :,1]\n",
    "    image_r_channel = image[:, :,0]\n",
    "    foreground = np.logical_or(image_g_channel < 180 , image_r_channel > 150)\n",
    "    nonzero_x , nonzero_y = np.nonzero(foreground)\n",
    "    nonzerocatvalues = image[nonzero_x, nonzero_y, : ]\n",
    "    new_frame = background.copy()\n",
    "    new_frame[nonzero_x, nonzero_y, :] = nonzerocatvalues\n",
    "    new_frame = new_frame[:,:,[2, 1, 0]]\n",
    "    imageslist.append(new_frame)\n",
    "clip = mpy.ImageSequenceClip( imageslist , fps = 25)\n",
    "audio = mpy.AudioFileClip('selfcontrol_part.wav').set_duration( clip.duration )\n",
    "clip = clip.set_audio(audioclip=audio )\n",
    "clip.write_videofile('part3_video.mp4', codec='libx264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 926, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "chunk:   0%|                                 | 0/159 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video part4_video.mp4.\n",
      "MoviePy - Writing audio in part4_videoTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|                                     | 0/181 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video part4_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready part4_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def calculate_cdf(hist):\n",
    "    cdf = hist.cumsum()\n",
    "    #cdf_normalized = cdf * hist.max()/ cdf.max() \n",
    "    cdf_normalized = cdf / float(cdf.max())\n",
    "    return cdf_normalized\n",
    "\n",
    "def lookup(source_cdf, target_cdf):\n",
    "    lookup_table = np.zeros(256)\n",
    "    lookup_val = 0\n",
    "    for g_I in range(len(source_cdf)):\n",
    "        for g_J in range(len(target_cdf)):\n",
    "            if target_cdf[g_J] >= source_cdf[g_I]:\n",
    "                lookup_val = g_J\n",
    "                break\n",
    "        lookup_table[g_I] = lookup_val\n",
    "    return lookup_table\n",
    "\n",
    "background = cv2.imread('Malibu.jpg')\n",
    "background_height = background.shape[0]\n",
    "background_width = background.shape[1]\n",
    "ratio = 360/background_height\n",
    "background = cv2.resize(background, (int(background_width*ratio),360))\n",
    "print(background.shape)\n",
    "\n",
    "target = cv2.imread('blue.jpg')\n",
    "\n",
    "b_h_list = []\n",
    "g_h_list = []\n",
    "r_h_list = []\n",
    "i = 0\n",
    "while 1:\n",
    "    image=cv2.imread('cat/cat_'+ str(i) + '.png')\n",
    "    if image is None:\n",
    "        break\n",
    "    i = i+1\n",
    "    \n",
    "    mirror_im = cv2.flip(image,1)\n",
    "    green_im = np.zeros((360,286,3), np.uint8)\n",
    "    green_im[:,0:286]= (0,255,0)\n",
    "    mirror_im = cv2.hconcat([green_im, mirror_im])\n",
    "    \n",
    "    mirror_g_channel = mirror_im[:, :, 1]\n",
    "    mirror_r_channel = mirror_im[:, :, 2]\n",
    "    mirror_b_channel = mirror_im[:, :, 0]\n",
    "    \n",
    "    mirror_hist_blue, bin_0 = np.histogram(mirror_b_channel.flatten(), 256, [0,256])\n",
    "    mirror_hist_green, bin_1 = np.histogram(mirror_g_channel.flatten(), 256, [0,256])\n",
    "    mirror_hist_red, bin_2 = np.histogram(mirror_r_channel.flatten(), 256, [0,256]) \n",
    "    \n",
    "    b_h_list.append(mirror_hist_blue)\n",
    "    g_h_list.append(mirror_hist_green)\n",
    "    r_h_list.append(mirror_hist_red)\n",
    "\n",
    "total_b = np.zeros_like(mirror_hist_blue)\n",
    "total_g = np.zeros_like(mirror_hist_green)\n",
    "total_r = np.zeros_like(mirror_hist_red)\n",
    "for a in b_h_list:\n",
    "    total_b = total_b + a\n",
    "for a in g_h_list:\n",
    "    total_g = total_g + a\n",
    "for a in r_h_list:\n",
    "    total_r = total_r + a\n",
    "\n",
    "#average cat histogram:\n",
    "average_b_histogram = total_b/i\n",
    "average_g_histogram = total_g/i\n",
    "average_r_histogram = total_r/i\n",
    "\n",
    "target_g_channel = target[:, :, 1]\n",
    "target_r_channel = target[:, :, 2]\n",
    "target_b_channel = target[:, :, 0]\n",
    "\n",
    "target_hist_blue, bin_3 = np.histogram(target_b_channel.flatten(), 256, [0,256])    \n",
    "target_hist_green, bin_4 = np.histogram(target_g_channel.flatten(), 256, [0,256])\n",
    "target_hist_red, bin_5 = np.histogram(target_r_channel.flatten(), 256, [0,256])\n",
    "\n",
    "source_cdf_blue = calculate_cdf(average_b_histogram)\n",
    "source_cdf_green = calculate_cdf(average_g_histogram)\n",
    "source_cdf_red = calculate_cdf(average_r_histogram)\n",
    "target_cdf_blue = calculate_cdf(target_hist_blue)\n",
    "target_cdf_green = calculate_cdf(target_hist_green)\n",
    "target_cdf_red = calculate_cdf(target_hist_red)\n",
    "\n",
    "blue_lookup_table = lookup(source_cdf_blue, target_cdf_blue)\n",
    "green_lookup_table = lookup(source_cdf_green, target_cdf_green)\n",
    "red_lookup_table = lookup(source_cdf_red, target_cdf_red)\n",
    "\n",
    "imageslist = []\n",
    "i = 0\n",
    "while 1:\n",
    "    image=cv2.imread('cat/cat_'+ str(i) + '.png')\n",
    "    if image is None:\n",
    "        break\n",
    "    i = i+1\n",
    "    \n",
    "    mirror_im = cv2.flip(image,1)\n",
    "    green_im = np.zeros((360,286,3), np.uint8)\n",
    "    green_im[:,0:286]= (0,255,0)\n",
    "    mirror_im = cv2.hconcat([green_im, mirror_im])\n",
    "    \n",
    "    mirror_g_channel = mirror_im[:, :, 1]\n",
    "    mirror_r_channel = mirror_im[:, :, 2]\n",
    "    mirror_b_channel = mirror_im[:, :, 0]\n",
    "    \n",
    "    b_after_transform = cv2.LUT(mirror_b_channel, blue_lookup_table)\n",
    "    g_after_transform = cv2.LUT(mirror_g_channel, green_lookup_table)\n",
    "    r_after_transform = cv2.LUT(mirror_r_channel, red_lookup_table)\n",
    "    \n",
    "    image_after_matching = cv2.merge([b_after_transform, g_after_transform, r_after_transform])\n",
    "    image_after_matching = cv2.convertScaleAbs(image_after_matching)\n",
    "    \n",
    "    with_myself = mirror_im.copy()\n",
    "    foreground = np.logical_or(mirror_g_channel < 180 , mirror_r_channel > 150)\n",
    "    n_x,n_y = np.nonzero(foreground)\n",
    "    purple_cat_values = image_after_matching[n_x, n_y, :]\n",
    "    with_myself[n_x,n_y, : ] = purple_cat_values\n",
    "    with_myself[0:image.shape[0],0:image.shape[1]-110,:] = image[0:image.shape[0],0:image.shape[1]-110,:]\n",
    " \n",
    "    image = with_myself\n",
    "    #same for the rest\n",
    "    image_g_channel = image[:, :,1]\n",
    "    image_r_channel = image[:, :,2]\n",
    "    foreground = np.logical_or(image_g_channel < 180 , image_r_channel > 150)\n",
    "    nonzero_x , nonzero_y = np.nonzero(foreground)\n",
    "    nonzerocatvalues = image[nonzero_x, nonzero_y, : ]\n",
    "    new_frame = background.copy()\n",
    "    new_frame[nonzero_x, nonzero_y, :] = nonzerocatvalues\n",
    "    new_frame = new_frame[:,:,[2, 1, 0]]\n",
    "    imageslist.append(new_frame)\n",
    "clip = mpy.ImageSequenceClip( imageslist , fps = 25)\n",
    "audio = mpy.AudioFileClip('selfcontrol_part.wav').set_duration( clip.duration )\n",
    "clip = clip.set_audio(audioclip=audio )\n",
    "clip.write_videofile('part4_video.mp4', codec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
